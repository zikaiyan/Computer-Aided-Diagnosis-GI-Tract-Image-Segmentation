{"cells":[{"cell_type":"markdown","id":"Pcd-9PDYytQu","metadata":{"id":"Pcd-9PDYytQu"},"source":["# Connect to Google Drive"]},{"cell_type":"code","execution_count":null,"id":"fuyvNAE_SYVl","metadata":{"id":"fuyvNAE_SYVl"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"id":"IHp48yTjSfRh","metadata":{"id":"IHp48yTjSfRh"},"outputs":[],"source":["import os\n","os.chdir('/content/drive/MyDrive/Portfolio/Projects/Course/Computer-Aided-Diagnosis-GI-Tract-Image-Segmentation')\n","!pwd"]},{"cell_type":"code","execution_count":null,"id":"S8aIgCGARYK6","metadata":{"id":"S8aIgCGARYK6"},"outputs":[],"source":["# Unzip files into the On the Fly Dataset\n","import zipfile\n","import os\n","\n","zip_path = '/content/drive/MyDrive/Portfolio/Projects/Course/Computer-Aided-Diagnosis-GI-Tract-Image-Segmentation/datasets/uw-madison-gi-tract-image-segmentation.zip'\n","extract_path = '/content/datasets'\n","\n","with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","    zip_ref.extractall(extract_path)\n","\n","print(\"Unzipped successfully!\")"]},{"cell_type":"markdown","id":"8557353f","metadata":{"id":"8557353f"},"source":["# Import Packages"]},{"cell_type":"code","execution_count":null,"id":"b80e01f6","metadata":{"id":"b80e01f6"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","from matplotlib import animation, rc\n","import imageio\n","import time\n","import cv2\n","from skimage.io import imread, imshow, imread_collection, concatenate_images\n","from skimage.transform import resize\n","import tensorflow as tf\n","from skimage.morphology import label\n","import random\n","from tqdm import tqdm\n","from torch.utils.data import DataLoader, Dataset\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","from sklearn.model_selection import StratifiedKFold\n","from skimage.segmentation import watershed\n","from skimage.measure import label\n","import matplotlib.pyplot as plt\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torch.nn as nn\n","import torch\n","import cv2\n","from albumentations.pytorch import ToTensorV2\n","import albumentations as A\n","import random\n","import pickle\n","import os\n","import collections\n","from sklearn.model_selection import train_test_split\n","import torchvision\n","from torchvision.transforms import ToPILImage\n","from torchvision.transforms import functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n","from tqdm import tqdm\n","import seaborn as sns\n","from scipy.spatial.distance import directed_hausdorff\n","SEED = 42"]},{"cell_type":"code","execution_count":null,"id":"3bcbeb9b","metadata":{"id":"3bcbeb9b"},"outputs":[],"source":["# Fix randomness\n","\n","def fix_all_seeds(seed):\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed_all(seed)\n","        torch.backends.cudnn.deterministic = True\n","\n","fix_all_seeds(SEED)"]},{"cell_type":"markdown","id":"piqzvFPOyj8S","metadata":{"id":"piqzvFPOyj8S"},"source":["# Config"]},{"cell_type":"code","execution_count":null,"id":"10E2zNbAyiqD","metadata":{"id":"10E2zNbAyiqD"},"outputs":[],"source":["PATH = '/content/datasets'\n","DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","BATCH_SIZE = 2\n","BATCH_SIZE_INFERENCE = 128\n","NUM_EPOCHS = 3\n","\n","WIDTH = 512\n","HEIGHT = 512\n","\n","resize_factor = True\n","flip_prob = 0.2\n","\n","# Normalize to resnet mean and std if True.\n","NORMALIZE = False\n","\n","RESNET_MEAN = (0.485, 0.456, 0.406)\n","RESNET_STD = (0.229, 0.224, 0.225)\n","\n","MOMENTUM = 0.9\n","LEARNING_RATE = 0.001\n","WEIGHT_DECAY = 0.0005\n","\n","# Changes the confidence required for a pixel to be kept for a mask.\n","cell_type_dict = {\"stomach\": 1, \"large_bowel\": 2, \"small_bowel\": 3}\n","idx_to_cell_type = {v: k for k, v in cell_type_dict.items()}\n","mask_threshold_dict = {1: 0.5, 2: 0.5, 3:  0.5}\n","min_score_dict = {1: 0.5, 2: 0.5, 3: 0.5}\n","\n","# Use a StepLR scheduler if True.\n","USE_SCHEDULER = False\n","\n","train_valid_ratio = 0.1\n","\n","BOX_DETECTIONS_PER_IMG = 100"]},{"cell_type":"markdown","id":"fb2867b2","metadata":{"id":"fb2867b2"},"source":["# Load Data"]},{"cell_type":"code","execution_count":null,"id":"UK-DPtQ2riHa","metadata":{"id":"UK-DPtQ2riHa"},"outputs":[],"source":["# load raw train data\n","raw_train_data = pd.read_csv('datasets/train.csv')\n","raw_train_data['case'] = raw_train_data['id'].apply(lambda x: x.split('_')[0])\n","raw_train_data['day'] = raw_train_data['id'].apply(lambda x: x.split('_')[1])\n","raw_train_data['slice'] = raw_train_data['id'].apply(lambda x: x.split('_')[2] + '_' + x.split('_')[3])\n","raw_train_data.head()"]},{"cell_type":"code","execution_count":null,"id":"-BvrOY9GyU-p","metadata":{"id":"-BvrOY9GyU-p"},"outputs":[],"source":["# Create train/val/test split based on slice\n","temp = raw_train_data.groupby(['id','class']).agg({'segmentation':'count'}).reset_index().pivot_table(index = 'id', columns = 'class', values = 'segmentation').reset_index()\n","temp['all 3 organs'] = temp[['large_bowel','small_bowel','stomach']].sum(axis = 1)\n","\n","df_images_train, df_images_temp = train_test_split(temp, stratify=temp['all 3 organs'],\n","                                                  test_size=0.35,\n","                                                  random_state=SEED)\n","\n","df_images_val, df_images_test = train_test_split(df_images_temp, stratify=df_images_temp['all 3 organs'],\n","                                                  test_size=0.5714,\n","                                                  random_state=SEED) # test_size ~ 57.14% of 35%\n","\n","\n","df_train = raw_train_data[(raw_train_data['id'].isin(df_images_train['id'])) & (raw_train_data['segmentation'].notna())]\n","df_val = raw_train_data[(raw_train_data['id'].isin(df_images_val['id'])) & (raw_train_data['segmentation'].notna())]\n","df_test = raw_train_data[(raw_train_data['id'].isin(df_images_test['id'])) & (raw_train_data['segmentation'].notna())]"]},{"cell_type":"code","execution_count":null,"id":"8ToVWXi2k200","metadata":{"id":"8ToVWXi2k200"},"outputs":[],"source":["# # Create train/val/test split based on mask\n","# # Extract information from data\n","# from src.data import SegmentationDataset\n","\n","# sd = SegmentationDataset(dataset_dir='/content/datasets/train',\n","#                          csv_file_path='/content/datasets/train.csv')\n","# df = sd.processed_df\n","\n","# random.seed(42)\n","\n","# # train - 65, val - 15, test - 20\n","# df_train, df_temp = train_test_split(df, test_size=0.35, random_state=42)\n","# df_val, df_test = train_test_split(df_temp, test_size=0.5714, random_state=42)  # test_size ~ 57.14% of 35%\n","\n","# df_train = df_train.reset_index(drop=True)\n","# df_val = df_val.reset_index(drop=True)\n","# df_test = df_test.reset_index(drop=True)"]},{"cell_type":"markdown","id":"46c0be7a","metadata":{"id":"46c0be7a"},"source":["# Data Preparation"]},{"cell_type":"code","execution_count":null,"id":"4a4afd71","metadata":{"id":"4a4afd71"},"outputs":[],"source":["# Helper functions\n","def rle_encoding(x):\n","    dots = np.where(x.flatten() == 1)[0]\n","    run_lengths = []\n","    prev = -2\n","    for b in dots:\n","        if (b>prev+1): run_lengths.extend((b + 1, 0))\n","        run_lengths[-1] += 1\n","        prev = b\n","    return ' '.join(map(str, run_lengths))\n","\n","\n","def remove_overlapping_pixels(mask, other_masks):\n","    for other_mask in other_masks:\n","        if np.sum(np.logical_and(mask, other_mask)) > 0:\n","            mask[np.logical_and(mask, other_mask)] = 0\n","    return mask\n","\n","def combine_masks(masks, mask_threshold):\n","    \"\"\"\n","    combine masks into one image\n","    \"\"\"\n","    masking = np.zeros((HEIGHT, WIDTH))\n","    # print(len(masks.shape), masks.shape)\n","    for m, mask in enumerate(masks,1):\n","        masking[mask>mask_threshold] = m\n","    return masking\n","\n","\n","def get_filtered_masks(pred):\n","    \"\"\"\n","    filter masks using MIN_SCORE for mask and MAX_THRESHOLD for pixels\n","    \"\"\"\n","    use_masks = []\n","    for i, mask in enumerate(pred[\"masks\"]):\n","\n","        # Filter-out low-scoring results. Not tried yet.\n","        scr = pred[\"scores\"][i].cpu().item()\n","        label = pred[\"labels\"][i].cpu().item()\n","        if scr > min_score_dict[label]:\n","            mask = mask.cpu().numpy().squeeze()\n","            # Keep only highly likely pixels\n","            binary_mask = mask > mask_threshold_dict[label]\n","            binary_mask = remove_overlapping_pixels(binary_mask, use_masks)\n","            use_masks.append(binary_mask)\n","\n","    return use_masks"]},{"cell_type":"code","source":["# Dice Loss and IoU for model evaluation (Aligned with UNet Models)\n","def DiceLoss(true_masks, pred_masks, smooth=1e-5):\n","    # Convert lists of [channels, height, width] to numpy arrays [size, channels, height, width]\n","    true_masks = np.stack(true_masks)\n","    pred_masks = np.stack(pred_masks)\n","\n","    # Calculate intersection and sum_area using broadcasting\n","    intersection = np.sum(np.logical_and(true_masks, pred_masks), axis=(2, 3))  # sum over height and width\n","    sum_area = np.sum(true_masks, axis=(2, 3)) + np.sum(pred_masks, axis=(2, 3))  # sum over height and width\n","\n","    # Compute dice coefficient\n","    dice_coeff = (2. * intersection + smooth) / (sum_area + smooth)\n","\n","    # Compute dice loss\n","    dice_loss = 1 - dice_coeff\n","\n","    # Average over all size and channels\n","    mean_dice_loss = np.mean(dice_loss)\n","\n","    return mean_dice_loss\n","\n","\n","def IoU(true_masks, pred_masks):\n","\n","    iou_values_0 = []\n","    iou_values_1 = []\n","    iou_values_2 = []\n","\n","    for idx in range(len(true_masks)):\n","        for ch in range(len(min_score_dict)):\n","            true_mask = true_masks[idx][ch, :, :]\n","            pred_mask = pred_masks[idx][ch, :, :]\n","\n","            if true_mask.sum() == 0:\n","                continue # skip cases where the truth is all zeros since we dont have ground truth\n","\n","            if true_mask.sum() == 0 and pred_mask.sum() == 0:\n","                continue # Skip channel if both truth and predictions are all zeros\n","\n","            intersection = np.logical_and(true_mask, pred_mask).sum()\n","            union = np.logical_or(true_mask, pred_mask).sum()\n","\n","            if union == 0:\n","                iou = 0\n","            else:\n","                iou = intersection / union\n","\n","            if ch == 0:\n","                iou_values_0.append(iou)\n","            elif ch == 1:\n","                iou_values_1.append(iou)\n","            else:\n","                iou_values_2.append(iou)\n","\n","    # Calculate mean avoiding empty lists\n","    mean_iou_0 = sum(iou_values_0) / len(iou_values_0) if iou_values_0 else 0\n","    mean_iou_1 = sum(iou_values_1) / len(iou_values_1) if iou_values_1 else 0\n","    mean_iou_2 = sum(iou_values_2) / len(iou_values_2) if iou_values_2 else 0\n","\n","    return mean_iou_0, mean_iou_1, mean_iou_2\n","\n","def ChannelwiseHausdorffDistanceLoss(true_masks, pred_masks):\n","    # Convert lists of [channels, height, width] to numpy arrays [size, channels, height, width]\n","    true_masks = np.stack(true_masks)\n","    pred_masks = np.stack(pred_masks)\n","\n","    size = pred_masks.shape[0]\n","    channels = pred_masks.shape[1]\n","    hausdorff_loss = 0.0\n","\n","    for i in range(size):\n","        channel_losses = []\n","        for ch in range(channels):\n","\n","            # Calculate directed Hausdorff distance for this channel\n","            d1 = directed_hausdorff(pred_masks[i, ch, :, :], true_masks[i, ch, :, :])[0]\n","            d2 = directed_hausdorff(true_masks[i, ch, :, :], pred_masks[i, ch, :, :])[0]\n","            channel_losses.append(max(d1, d2))\n","\n","        # Average or max the channel-wise Hausdorff distances\n","        # You can choose max, mean or any other aggregation depending on the use case\n","        hausdorff_loss += np.mean(channel_losses)\n","\n","    return hausdorff_loss / size\n","\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count"],"metadata":{"id":"3-Bg_YmbaU4L"},"id":"3-Bg_YmbaU4L","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"5ebbf0a0","metadata":{"id":"5ebbf0a0"},"outputs":[],"source":["#Metric: mean of the precision values at each IoU threshold\n","#Ref: https://www.kaggle.com/theoviel/competition-metric-map-iou\n","\n","def compute_iou(labels, y_pred, verbose=0):\n","    \"\"\"\n","    Computes the IoU for instance labels and predictions.\n","\n","    Args:\n","        labels (np array): Labels.\n","        y_pred (np array): predictions\n","\n","    Returns:\n","        np array: IoU matrix, of size true_objects x pred_objects.\n","    \"\"\"\n","\n","    true_objects = len(np.unique(labels))\n","    pred_objects = len(np.unique(y_pred))\n","\n","    if verbose:\n","        print(\"Number of true objects: {}\".format(true_objects))\n","        print(\"Number of predicted objects: {}\".format(pred_objects))\n","\n","    # Compute intersection between all objects\n","    intersection = np.histogram2d(\n","        labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects)\n","    )[0]\n","\n","    # Compute areas (needed for finding the union between all objects)\n","    area_true = np.histogram(labels, bins=true_objects)[0]\n","    area_pred = np.histogram(y_pred, bins=pred_objects)[0]\n","    area_true = np.expand_dims(area_true, -1)\n","    area_pred = np.expand_dims(area_pred, 0)\n","\n","    # Compute union\n","    union = area_true + area_pred - intersection\n","    intersection = intersection[1:, 1:] # exclude background\n","    union = union[1:, 1:]\n","    union[union == 0] = 1e-9\n","    iou = intersection / union\n","\n","    return iou\n","\n","def precision_at(threshold, iou):\n","    \"\"\"\n","    Computes the precision at a given threshold.\n","\n","    Args:\n","        threshold (float): Threshold.\n","        iou (np array): IoU matrix.\n","\n","    Returns:\n","        int: Number of true positives,\n","        int: Number of false positives,\n","        int: Number of false negatives.\n","    \"\"\"\n","    matches = iou > threshold\n","    true_positives = np.sum(matches, axis=1) == 1  # Correct objects\n","    false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n","    false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n","    tp, fp, fn = (\n","        np.sum(true_positives),\n","        np.sum(false_positives),\n","        np.sum(false_negatives),\n","    )\n","    return tp, fp, fn\n","\n","def iou_map(truths, preds, verbose=0):\n","    \"\"\"\n","    Computes IOU.\n","    Masks contain the segmented pixels where each object has one value associated,\n","    and 0 is the background.\n","\n","    Args:\n","        truths (list of masks): Ground truths.\n","        preds (list of masks): Predictions.\n","        verbose (int, optional): Whether to print infos. Defaults to 0.\n","\n","    Returns:\n","        float: mAP.\n","    \"\"\"\n","    ious = [compute_iou(truth, pred, verbose) for truth, pred in zip(truths, preds)]\n","\n","    if verbose:\n","        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n","\n","    prec = []\n","    for t in np.arange(0.5, 1.0, 0.05):\n","        tps, fps, fns = 0, 0, 0\n","        for iou in ious:\n","            tp, fp, fn = precision_at(t, iou)\n","            tps += tp\n","            fps += fp\n","            fns += fn\n","\n","        p = tps / (tps + fps + fns)\n","        prec.append(p)\n","\n","        if verbose:\n","            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tps, fps, fns, p))\n","\n","    if verbose:\n","        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n","\n","    return np.mean(prec)\n","\n","\n","def get_score(ds, mdl, threshold_dict):\n","    \"\"\"\n","    Get average IOU mAP score for a dataset\n","    \"\"\"\n","    mdl.eval()\n","    iouscore = 0\n","    for i in tqdm(range(len(ds))):\n","        img, targets = ds[i]\n","        with torch.no_grad():\n","            result = mdl([img.to(DEVICE)])[0]\n","\n","        masks = combine_masks(targets['masks'], 0.5)\n","        labels = pd.Series(result['labels'].cpu().numpy()).value_counts()\n","\n","        mask_threshold = threshold_dict[labels.sort_values().index[-1]]\n","        pred_masks = combine_masks(get_filtered_masks(result), mask_threshold)\n","        iouscore += iou_map([masks],[pred_masks])\n","    return iouscore / len(ds)"]},{"cell_type":"code","execution_count":null,"id":"049ba205","metadata":{"id":"049ba205"},"outputs":[],"source":["class Compose:\n","    def __init__(self, transforms):\n","        self.transforms = transforms\n","\n","    def __call__(self, image, target):\n","        for t in self.transforms:\n","            image, target = t(image, target)\n","        return image, target\n","\n","class VerticalFlip:\n","    def __init__(self, prob):\n","        self.prob = prob\n","\n","    def __call__(self, image, target):\n","        if random.random() < self.prob:\n","            height, width = image.shape[-2:]\n","            image = image.flip(-2)\n","            bbox = target[\"boxes\"]\n","            bbox[:, [1, 3]] = height - bbox[:, [3, 1]]\n","            target[\"boxes\"] = bbox\n","            target[\"masks\"] = target[\"masks\"].flip(-2)\n","        return image, target\n","\n","class HorizontalFlip:\n","    def __init__(self, prob):\n","        self.prob = prob\n","\n","    def __call__(self, image, target):\n","        if random.random() < self.prob:\n","            height, width = image.shape[-2:]\n","            image = image.flip(-1)\n","            bbox = target[\"boxes\"]\n","            bbox[:, [0, 2]] = width - bbox[:, [2, 0]]\n","            target[\"boxes\"] = bbox\n","            target[\"masks\"] = target[\"masks\"].flip(-1)\n","        return image, target\n","\n","class Normalize:\n","    def __call__(self, image, target):\n","        image = F.normalize(image, RESNET_MEAN, RESNET_STD)\n","        return image, target\n","\n","class ToTensor:\n","    def __call__(self, image, target):\n","        image = F.to_tensor(image)\n","        return image, target\n","\n","\n","def get_transform(train):\n","    transforms = [ToTensor()]\n","    if NORMALIZE:\n","        transforms.append(Normalize())\n","\n","    # Data augmentation for train\n","    if train:\n","        transforms.append(HorizontalFlip(flip_prob))\n","        transforms.append(VerticalFlip(flip_prob))\n","\n","    return Compose(transforms)"]},{"cell_type":"code","execution_count":null,"id":"deffbf3a","metadata":{"id":"deffbf3a"},"outputs":[],"source":["class ImageDataset(Dataset):\n","    def __init__(self, image_dir, df, train_flag=None, transforms=None, resize=False):\n","        self.transforms = transforms\n","        self.image_dir = image_dir\n","        self.df = df\n","        self.train_flag = train_flag\n","\n","        self.should_resize = resize is not False\n","        if self.should_resize:\n","            self.height = int(HEIGHT * resize)\n","            self.width = int(WIDTH * resize)\n","            print(\"image size used:\", self.height, self.width)\n","        else:\n","            self.height = HEIGHT\n","            self.width = WIDTH\n","\n","        self.image_info = collections.defaultdict(dict)\n","\n","        df_temp = self.df.groupby([\"id\"])['segmentation'].agg(lambda x: list(x)).reset_index().merge(self.df.groupby([\"id\"])['class'].agg(lambda x: list(x)).reset_index(), how = 'left', on = 'id')\n","\n","        for index, row in df_temp.iterrows():\n","            sample_id = row['id']\n","            case_num = sample_id.split('_')[0]\n","            day_num = sample_id.split('_')[1]\n","            slice_num = [x for x in os.listdir(f'/content/datasets/train/{case_num}/{case_num + \"_\" + day_num}/scans/') if sample_id.split('_')[3] in x.split('_')[1]][0]\n","            path = f'{self.image_dir}/train/{case_num}/{case_num + \"_\" + day_num}/scans/{slice_num}'\n","            self.image_info[index] = {\n","                    'image_id': row['id'],\n","                    'image_path': path,\n","                    'annotations': row[\"segmentation\"],\n","                    'class': [cell_type_dict[x] for x in row[\"class\"]]\n","                    }\n","\n","    def get_box(self, a_mask):\n","        ''' Get the bounding box of a given mask '''\n","        pos = np.where(a_mask)\n","        xmin = np.min(pos[1])\n","        xmax = np.max(pos[1])\n","        ymin = np.min(pos[0])\n","        ymax = np.max(pos[0])\n","        return [xmin, ymin, xmax, ymax]\n","\n","    def __getitem__(self, idx):\n","        ''' Get the image and the target'''\n","\n","        img_path = self.image_info[idx][\"image_path\"]\n","        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n","        initial_HEIGHT = img.shape[0]\n","        initial_WIDTH = img.shape[1]\n","\n","        if self.should_resize:\n","            img = cv2.resize(img, (self.width, self.height))\n","\n","        info = self.image_info[idx]\n","\n","        n_objects = len(info['annotations'])\n","        masks = np.zeros((len(info['annotations']), self.height, self.width), dtype=np.uint8)\n","        boxes = []\n","        labels = []\n","        for i, annotation in enumerate(info['annotations']):\n","            a_mask = rle_decode(annotation, (initial_HEIGHT, initial_WIDTH))\n","\n","            if self.should_resize:\n","                a_mask = cv2.resize(a_mask, (self.width, self.height))\n","\n","            a_mask = np.array(a_mask) > 0\n","            masks[i, :, :] = a_mask\n","\n","            boxes.append(self.get_box(a_mask))\n","\n","        # labels\n","        labels = [int(info[\"class\"][m]) for m in range(0, (n_objects))]\n","\n","        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n","        labels = torch.as_tensor(labels, dtype=torch.int64)\n","        masks = torch.as_tensor(masks, dtype=torch.uint8)\n","\n","        image_id = torch.tensor([idx])\n","        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n","        iscrowd = torch.zeros((n_objects,), dtype=torch.int64)\n","\n","        if self.train_flag == 'train':\n","            # This is the required target for the Mask R-CNN\n","            target = {\n","                'boxes': boxes,\n","                'labels': labels,\n","                'masks': masks,\n","                'image_id': image_id,\n","                'area': area,\n","                'iscrowd': iscrowd\n","            }\n","        else:\n","            target = {\n","                'boxes': boxes,\n","                'labels': labels,\n","                'masks': masks,\n","                'image_id': image_id,\n","                'area': area,\n","                'iscrowd': iscrowd,\n","                'image_path':img_path,\n","                'initial_HEIGHT': initial_HEIGHT,\n","                'initial_WIDTH': initial_WIDTH\n","            }\n","\n","        if self.transforms is not None:\n","            img, target = self.transforms(img, target)\n","\n","        return img, target\n","\n","    def __len__(self):\n","        return len(self.image_info)"]},{"cell_type":"code","execution_count":null,"id":"9tF2ufK4nCEK","metadata":{"id":"9tF2ufK4nCEK"},"outputs":[],"source":["ds_train = ImageDataset(PATH, df_train, train_flag = 'train', resize=resize_factor, transforms=get_transform(train=False))\n","dl_train = DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True,\n","                      num_workers=2, collate_fn=lambda x: tuple(zip(*x)))\n","\n","ds_val = ImageDataset(PATH, df_val, train_flag = 'train', resize=resize_factor, transforms=get_transform(train=False))\n","dl_val = DataLoader(ds_val, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True,\n","                    num_workers=2, collate_fn=lambda x: tuple(zip(*x)))\n","\n","ds_test = ImageDataset(PATH, df_test, train_flag = 'train', resize=resize_factor, transforms=get_transform(train=False))\n","dl_test = DataLoader(ds_test, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True,\n","                     num_workers=2, collate_fn=lambda x: tuple(zip(*x)))"]},{"cell_type":"markdown","id":"6859f408","metadata":{"id":"6859f408"},"source":["# Visualization"]},{"cell_type":"code","execution_count":null,"id":"ff7ceb2d","metadata":{"id":"ff7ceb2d"},"outputs":[],"source":["# Helper functions\n","def rle_decode(mask_rle, shape, color=1):\n","    '''\n","    mask_rle: run-length as string formated (start length)\n","    shape: (height, width, channels) of array to return\n","    color: color for the mask\n","    Returns numpy array (mask)\n","    '''\n","    s = mask_rle.split()\n","\n","    starts = list(map(lambda x: int(x) - 1, s[0::2]))\n","    lengths = list(map(int, s[1::2]))\n","    ends = [x + y for x, y in zip(starts, lengths)]\n","\n","    if len(shape)==3:\n","        img = np.zeros((shape[0] * shape[1], shape[2]), dtype=np.float32)\n","    else:\n","        img = np.zeros(shape[0] * shape[1], dtype=np.float32)\n","\n","    for start, end in zip(starts, ends):\n","        img[start : end] = color\n","\n","    return img.reshape(shape)"]},{"cell_type":"code","execution_count":null,"id":"inp0SlQax6Rh","metadata":{"id":"inp0SlQax6Rh"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from matplotlib.colors import ListedColormap\n","import matplotlib.patches as mpatches\n","\n","def plot_image(image, target=None):\n","    # Create custom colormaps for the masks\n","    cmap1 = ListedColormap(['none', 'red'])  # Mask 1 in red\n","    cmap2 = ListedColormap(['none', 'green'])  # Mask 2 in green\n","    cmap3 = ListedColormap(['none', 'blue'])  # Mask 3 in blue\n","\n","    fig, ax = plt.subplots()\n","    # Display the grayscale image\n","    ax.imshow((image)[0, :, :], cmap='gray')\n","\n","    if target is not None:\n","        # Display masks\n","        for i in range(len(target['labels'])):\n","            if target['labels'][i] == 3: # Large Bowel\n","                ax.imshow(target['masks'][i, :, :], cmap=cmap1, alpha=0.5)\n","            elif target['labels'][i] == 2: # Small Bowl\n","                ax.imshow(target['masks'][i, :, :], cmap=cmap2, alpha=0.5)\n","            else: # Stomach\n","                ax.imshow(target['masks'][i, :, :], cmap=cmap3, alpha=0.5)\n","\n","        # Create a legend for the masks\n","        red_patch = mpatches.Patch(color='red', label='Small Bowel')\n","        green_patch = mpatches.Patch(color='green', label='Large Bowel')\n","        blue_patch = mpatches.Patch(color='blue', label='Stomach')\n","        plt.legend(handles=[red_patch, green_patch, blue_patch])\n","\n","    # Show the plot\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"id":"-QLCYzFYx7GF","metadata":{"id":"-QLCYzFYx7GF"},"outputs":[],"source":["idx =100 # Change index to see different slice\n","image = ds_train[idx][0]\n","target = ds_train[idx][1]\n","plot_image(image, target)"]},{"cell_type":"code","execution_count":null,"id":"5e2a2bad","metadata":{"id":"5e2a2bad"},"outputs":[],"source":["# # Show animation\n","\n","# rc('animation', html='jshtml')\n","\n","# def create_animation(ims):\n","#     print('# Images:', len(ims))\n","#     fig = plt.figure(figsize=(6, 6))\n","#     plt.axis('off')\n","#     im = plt.imshow(ims[0], cmap=\"gray\")\n","\n","#     def animate_func(i):\n","#         im.set_array(ims[i])\n","#         return [im]\n","\n","#     return animation.FuncAnimation(fig, animate_func, frames = len(ims), interval = 1)\n","\n","# # See images for a case number and day number\n","# case_num = 'case123'\n","# day_num = 'day0'\n","# list_images_data = []\n","# for images in os.listdir(f'/content/datasets/train/{case_num}/{case_num}_{day_num}/scans/'):\n","#     image_data = plt.imread(f'/content/datasets/train/{case_num}/{case_num}_{day_num}/scans/' + images)\n","#     list_images_data.append(image_data)\n","# create_animation(list_images_data)"]},{"cell_type":"markdown","id":"a9cc3d8c","metadata":{"id":"a9cc3d8c"},"source":["# Modelling"]},{"cell_type":"markdown","id":"LbaiuQ1CzTYN","metadata":{"id":"LbaiuQ1CzTYN"},"source":["## Model Loading"]},{"cell_type":"code","execution_count":null,"id":"c237edb8","metadata":{"id":"c237edb8"},"outputs":[],"source":["def get_model(num_classes, model_chkpt=None):\n","    # This is just a dummy value for the classification head\n","\n","    if NORMALIZE:\n","        model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=True,\n","                                                                   box_detections_per_img=BOX_DETECTIONS_PER_IMG,\n","                                                                   image_mean=RESNET_MEAN,\n","                                                                   image_std=RESNET_STD)\n","    else:\n","        model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=True,\n","                                                                   box_detections_per_img=BOX_DETECTIONS_PER_IMG)\n","\n","    # get the number of input features for the classifier\n","    in_features = model.roi_heads.box_predictor.cls_score.in_features\n","    # replace the pre-trained head with a new one\n","    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes+1)\n","\n","    # now get the number of input features for the mask classifier\n","    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n","    hidden_layer = 256\n","    # and replace the mask predictor with a new one\n","    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, hidden_layer, num_classes+1)\n","\n","    if model_chkpt:\n","        model.load_state_dict(torch.load(model_chkpt, map_location=DEVICE))\n","    return model"]},{"cell_type":"code","execution_count":null,"id":"vMH7wiJhE1_A","metadata":{"id":"vMH7wiJhE1_A"},"outputs":[],"source":["# Get the Mask R-CNN model\n","# The model does classification, bounding boxes and MASKs for individuals, all at the same time\n","# We only care about MASKS\n","\n","# Initialize a new model or load a trained model for further training\n","e = 12\n","\n","if e > 0:\n","    model_chk = f\"mask-rcnn-trained/pytorch_model-e{e}.bin\"\n","    print(\"Loading:\", model_chk)\n","    model = get_model(len(cell_type_dict), model_chk)\n","    model.load_state_dict(torch.load(model_chk))\n","    model = model.to(DEVICE)\n","else:\n","    model = get_model(len(cell_type_dict))\n","    model = model.to(DEVICE)\n","\n","# Turn model into training mode\n","for param in model.parameters():\n","    param.requires_grad = True\n","model.train()"]},{"cell_type":"markdown","id":"624dcf77","metadata":{"id":"624dcf77"},"source":["## Model Training"]},{"cell_type":"code","execution_count":null,"id":"9fdb9e02","metadata":{"id":"9fdb9e02"},"outputs":[],"source":["TRAIN = False"]},{"cell_type":"code","execution_count":null,"id":"12b08a0c","metadata":{"id":"12b08a0c"},"outputs":[],"source":["if TRAIN:\n","    # Initialize\n","    params = [p for p in model.parameters() if p.requires_grad]\n","    optimizer = torch.optim.SGD(params, lr=LEARNING_RATE, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n","    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n","\n","    # Number of batches\n","    n_batches, n_batches_val = len(dl_train), len(dl_val)\n","\n","    # Tract Loss\n","    epoch_nbr = []\n","    train_losses = []\n","    train_mask_losses = []\n","    val_losses = []\n","    val_mask_losses = []\n","\n","    for epoch in range(1, NUM_EPOCHS + 1):\n","        # Set to train mode\n","        model.train()\n","\n","        print(f\"Starting epoch {epoch} of {NUM_EPOCHS}\")\n","        epoch_nbr.append(epoch)\n","\n","        time_start = time.time()\n","        loss_accum = 0.0\n","        loss_mask_accum = 0.0\n","\n","        for batch_idx, (images, targets) in enumerate(tqdm(dl_train), 1):\n","            # Predict\n","            images = list(image.to(DEVICE) for image in images)\n","            targets = [{k: v.to(DEVICE) for k, v in t.items()} for t in targets]\n","\n","            # Forward pass\n","            loss_dict = model(images, targets)\n","            loss = sum(loss for loss in loss_dict.values())\n","\n","            # Backprop\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            # Logging\n","            loss_accum += loss.item()\n","            loss_mask_accum += loss_dict['loss_mask'].item()\n","\n","            if batch_idx % 500 == 0:\n","                print(f\"[Batch {batch_idx:3d} / {n_batches:3d}] Batch train loss: {loss.item():7.3f}. {time.time() - time_start:.0f} secs\")\n","\n","        if USE_SCHEDULER:\n","            lr_scheduler.step()\n","\n","        # Train losses\n","        train_loss = loss_accum / n_batches\n","        train_loss_mask = loss_mask_accum / n_batches\n","\n","        # Store train losses\n","        train_losses.append(train_loss)\n","        train_mask_losses.append(train_loss_mask)\n","\n","        # Validation\n","        val_loss_accum = 0\n","        val_loss_mask_accum = 0\n","\n","        with torch.no_grad():\n","            for batch_idx, (images, targets) in enumerate(tqdm(dl_val), 1):  # Use tqdm here\n","                images = list(image.to(DEVICE) for image in images)\n","                targets = [{k: v.to(DEVICE) for k, v in t.items()} for t in targets]\n","\n","                val_loss_dict = model(images, targets)\n","                val_batch_loss = sum(loss for loss in val_loss_dict.values())\n","                val_loss_accum += val_batch_loss.item()\n","                val_loss_mask_accum += val_loss_dict['loss_mask'].item()\n","\n","        # Validation losses\n","        val_loss = val_loss_accum / n_batches_val\n","        val_loss_mask = val_loss_mask_accum / n_batches_val\n","        elapsed = time.time() - time_start\n","\n","        # Store validation losses\n","        val_losses.append(val_loss)\n","        val_mask_losses.append(val_loss_mask)\n","\n","        # Save model\n","        torch.save(model.state_dict(), f\"mask-rcnn-trained/pytorch_model-e{e + epoch}.bin\")\n","\n","        # Print result\n","        prefix = f\"[Epoch {epoch:2d} / {NUM_EPOCHS:2d}]\"\n","        print(f\"{prefix} Train loss: {train_loss:7.3f}. Val loss: {val_loss:7.3f} [{elapsed:.0f} secs]\")\n","        print(f\"{prefix} Train mask loss: {train_loss_mask:7.3f}, Val mask loss: {val_loss_mask:7.3f}\")\n","\n","    # Export Losses\n","    losses = {\n","        'epoch_nbr': [e + epoch_idx for epoch_idx in epoch_nbr],\n","        'train_losses': train_losses,\n","        'train_mask_losses': train_mask_losses,\n","        'val_losses': val_losses,\n","        'val_mask_losses': val_mask_losses\n","    }\n","    df_losses = pd.DataFrame(losses)\n","\n","    # Check existing file\n","    if os.path.isfile(\"output/losses/maskrcnn_losses.csv\"):\n","        existing_df = pd.read_csv(\"output/losses/maskrcnn_losses.csv\")\n","        df_losses = pd.concat([existing_df, df_losses], ignore_index=True)\n","        df_losses.to_csv(\"output/losses/maskrcnn_losses.csv\", index=False)\n","    else:\n","        df_losses.to_csv(\"output/losses/maskrcnn_losses.csv\", index=False)"]},{"cell_type":"markdown","id":"10UaPpAk_uSF","metadata":{"id":"10UaPpAk_uSF"},"source":["## Visualize Training Process"]},{"cell_type":"code","execution_count":null,"id":"8-gBQwlc_yT-","metadata":{"id":"8-gBQwlc_yT-"},"outputs":[],"source":["# Load the data\n","df_losses = pd.read_csv(\"output/losses/maskrcnn_losses.csv\")\n","\n","# Plotting\n","plt.figure(figsize=(15, 5))\n","\n","# Total Losses Plot\n","plt.subplot(1, 1, 1)\n","sns.lineplot(data=df_losses, x='epoch_nbr', y='train_losses', label='Train Losses')\n","sns.lineplot(data=df_losses, x='epoch_nbr', y='val_losses', label='Validation Losses')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Losses')\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","id":"StgTRGjsMGyl","metadata":{"id":"StgTRGjsMGyl"},"source":["# Data & Model Preparation for Inference"]},{"cell_type":"code","execution_count":null,"id":"dQg3PQPgM-T6","metadata":{"id":"dQg3PQPgM-T6"},"outputs":[],"source":["# Load trained model\n","e = 8\n","model_chk = f\"mask-rcnn-trained/pytorch_model-e{e}.bin\"\n","print(\"Loading:\", model_chk)\n","model = get_model(len(cell_type_dict), model_chk)\n","model.load_state_dict(torch.load(model_chk))\n","model = model.to(DEVICE)"]},{"cell_type":"code","execution_count":null,"id":"8FGbYTRwMJHi","metadata":{"id":"8FGbYTRwMJHi"},"outputs":[],"source":["# Load data for inference\n","## !!!Warning: Here we load data for inference purpose. It will replace original datasets to save memory resources.\n","## !!!Warning: If want to train the model, need to go back to \"Data Preparation\" and load data for training again.\n","ds_train = ImageDataset(PATH, df_train, train_flag = None, resize=resize_factor, transforms=get_transform(train=False))\n","dl_train = DataLoader(ds_train, batch_size=BATCH_SIZE_INFERENCE, shuffle=False, pin_memory=True,\n","                      num_workers=2, collate_fn=lambda x: tuple(zip(*x)))\n","\n","ds_val = ImageDataset(PATH, df_val, train_flag = None, resize=resize_factor, transforms=get_transform(train=False))\n","dl_val = DataLoader(ds_val, batch_size=BATCH_SIZE_INFERENCE, shuffle=False, pin_memory=True,\n","                    num_workers=2, collate_fn=lambda x: tuple(zip(*x)))\n","\n","ds_test = ImageDataset(PATH, df_test, train_flag = None, resize=resize_factor, transforms=get_transform(train=False))\n","dl_test = DataLoader(ds_test, batch_size=BATCH_SIZE_INFERENCE, shuffle=False, pin_memory=True,\n","                    num_workers=2, collate_fn=lambda x: tuple(zip(*x)))"]},{"cell_type":"markdown","id":"e39b4d0b","metadata":{"id":"e39b4d0b"},"source":["# Result Visualization"]},{"cell_type":"code","execution_count":null,"id":"Yo77DY8ZILIZ","metadata":{"id":"Yo77DY8ZILIZ"},"outputs":[],"source":["VISUALIZE_RESULTS = True"]},{"cell_type":"code","execution_count":null,"id":"hxWQOjp7FHJQ","metadata":{"id":"hxWQOjp7FHJQ"},"outputs":[],"source":["def compare_truth_pred(model, dataset, sample_index):\n","    # Froze model parameters and set it to evaluation mode\n","    for param in model.parameters():\n","        param.requires_grad = False\n","\n","    model.eval();\n","\n","    # Create custom colormaps for the masks\n","    cmap1 = ListedColormap(['none', 'red'])  # Mask 1 in red\n","    cmap2 = ListedColormap(['none', 'green'])  # Mask 2 in green\n","    cmap3 = ListedColormap(['none', 'blue'])  # Mask 3 in blue\n","    red_patch = mpatches.Patch(color='red', label='Small Bowel')\n","    green_patch = mpatches.Patch(color='green', label='Large Bowel')\n","    blue_patch = mpatches.Patch(color='blue', label='Stomach')\n","\n","    # Retrieve the image and target (labels and masks) for the given index from the training dataset\n","    img, target = dataset[sample_index]\n","    image_id = target['image_id']  # ID of the image\n","    initial_HEIGHT = target['initial_HEIGHT']  # Original height of the image\n","    initial_WIDTH = target['initial_WIDTH']  # Original width of the image\n","\n","    # Set up a matplotlib figure with three subplots to display the original image, ground truth, and predictions\n","    fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(20,60), facecolor=\"#fefefe\")\n","\n","    # Plot original image\n","    ax[0].imshow(img[0,:,:], cmap = 'gray')\n","    ax[0].set_title(f\"Original Image (Id:{sample_index})\")\n","    ax[0].axis(\"off\")\n","\n","    # Plot ground truth masks\n","    ax[1].imshow(img[0,:,:], cmap = 'gray')\n","    ax[1].set_title(f\"Ground Truth (Id:{sample_index})\")\n","    ax[1].axis(\"off\")\n","\n","    # Display masks\n","    for i in range(len(target['labels'])):\n","        if target['labels'][i] == 3: # Large Bowel\n","            ax[1].imshow(target['masks'][i, :, :], cmap=cmap1, alpha=0.5)\n","        elif target['labels'][i] == 2: # Small Bowl\n","            ax[1].imshow(target['masks'][i, :, :], cmap=cmap2, alpha=0.5)\n","        else: # Stomach\n","            ax[1].imshow(target['masks'][i, :, :], cmap=cmap3, alpha=0.5)\n","\n","    # Create a legend for the masks\n","    ax[1].legend(handles=[red_patch, green_patch, blue_patch])\n","\n","    # Plot predicted masks\n","    ax[2].imshow(img[0,:,:], cmap = 'gray')\n","    ax[2].set_title(f\"Predictions (Id:{sample_index})\")\n","    ax[2].axis(\"off\")\n","\n","    # Set the model to evaluation mode to disable layers like dropout and batch normalization\n","    model.eval()\n","    with torch.no_grad():\n","        # Make predictions using the model\n","        preds = model([img.to(DEVICE)])[0]\n","\n","    # Process results for each type of cell\n","    for cell_type in range(1, len(min_score_dict)+1):\n","        previous_masks = []  # List to store previous masks for overlap removal\n","        for i, mask in enumerate(preds[\"masks\"]):\n","            # Filter out results with a score below the threshold\n","            score = preds[\"scores\"][i].cpu().item()\n","            label = preds[\"labels\"][i].cpu().item()\n","            if (score > min_score_dict[label]) and (label == cell_type):\n","                mask = mask.cpu().numpy()  # Convert mask to numpy array\n","                # Threshold mask to create binary mask\n","                binary_mask = mask > mask_threshold_dict[label]\n","                # Remove overlapping pixels\n","                binary_mask = remove_overlapping_pixels(binary_mask, previous_masks)\n","                previous_masks.append(binary_mask)\n","\n","        # Flatten list of previous masks and create a binary mask for all cells of a type\n","        previous_masks = torch.tensor(np.array([item for sublist in previous_masks for item in sublist], dtype=int))\n","        binary_mask = np.zeros((HEIGHT, WIDTH))\n","        for m, mask in enumerate(previous_masks, 1):\n","            binary_mask[mask > 0.5] = 1\n","\n","        # Display masks\n","        if cell_type == 3: # Large Bowel\n","            ax[2].imshow(binary_mask, cmap=cmap1, alpha=0.5)\n","        elif cell_type == 2: # Small Bowl\n","            ax[2].imshow(binary_mask, cmap=cmap2, alpha=0.5)\n","        else: # Stomach\n","            ax[2].imshow(binary_mask, cmap=cmap3, alpha=0.5)\n","\n","    # Create a legend for the masks\n","    ax[2].legend(handles=[red_patch, green_patch, blue_patch])\n","\n","    # Show the plot\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"id":"BtOc94R-YBPX","metadata":{"id":"BtOc94R-YBPX"},"outputs":[],"source":["# Example usage:\n","for index in range(100, 103):\n","    compare_truth_pred(model, ds_val, index)"]},{"cell_type":"markdown","id":"160b3cf3","metadata":{"id":"160b3cf3"},"source":["# Inference"]},{"cell_type":"code","execution_count":null,"id":"i__lpd6QH2xF","metadata":{"id":"i__lpd6QH2xF"},"outputs":[],"source":["INFERENCE = True"]},{"cell_type":"code","source":["def inference(model, images, targets):\n","    # Froze model parameters and set it to evaluation mode\n","    for param in model.parameters():\n","        param.requires_grad = False\n","\n","    model.eval();\n","\n","    # Initialize a list to store prediction results\n","    predictions = []\n","    true_masks = []\n","    pred_masks = []\n","\n","    # Iterate over the dataset using tqdm for progress bar visualization\n","    for num in tqdm(range(len(images))):\n","        # Retrieve the image for the current sample\n","        img = images[num]  # The image data\n","        image_id = targets[num]['image_id']  # ID of the image\n","        initial_HEIGHT = targets[num]['initial_HEIGHT']  # Original height of the image\n","        initial_WIDTH = targets[num]['initial_WIDTH']  # Original width of the image\n","\n","        # Append masks\n","        true_masks.append(np.zeros((3, HEIGHT, WIDTH)))\n","        pred_masks.append(np.zeros((3, HEIGHT, WIDTH)))\n","        # Add ground truth masks to the list\n","        for i in range(len(targets[num]['labels'])):\n","            true_masks[num][targets[num]['labels'][i]-1, :, :] = targets[num]['masks'][i, :, :]\n","\n","\n","        # No gradient is needed for inference, thus wrap in torch.no_grad()\n","        with torch.no_grad():\n","            preds = model([img.to(DEVICE)])[0]  # Perform inference\n","\n","        # Process predictions for each type of cell\n","        for cell_type in range(1, len(min_score_dict)+1):\n","            previous_masks = []  # List to store previous masks for overlap removal\n","            for i, mask in enumerate(preds[\"masks\"]):\n","                # Filter out predictions with a score below the threshold\n","                score = preds[\"scores\"][i].cpu().item()\n","                label = preds[\"labels\"][i].cpu().item()\n","                if (score > min_score_dict[label]) and (label == cell_type):\n","                    mask = mask.cpu().numpy()  # Convert mask to numpy array\n","                    # Resize mask back to the original image dimensions\n","                    mask = cv2.resize(mask.reshape((HEIGHT, WIDTH, 1)), (initial_WIDTH, initial_HEIGHT))[None, :, :]\n","                    # Threshold mask to create binary mask\n","                    binary_mask = mask > mask_threshold_dict[label]\n","                    # Remove overlapping pixels\n","                    binary_mask = remove_overlapping_pixels(binary_mask, previous_masks)\n","                    previous_masks.append(binary_mask)\n","\n","            # Flatten list of previous masks and create a binary mask for all cells of a type\n","            previous_masks = torch.tensor(np.array([item for sublist in previous_masks for item in sublist], dtype=int))\n","            binary_mask = np.zeros((initial_HEIGHT, initial_WIDTH))\n","            for m, mask in enumerate(previous_masks, 1):\n","                binary_mask[mask > 0.5] = 1\n","            # Encode the binary mask using run-length encoding\n","            rle = rle_encoding(binary_mask)\n","            # Append the prediction (image ID, cell type, and RLE)\n","            predictions.append((image_id, {v: k for k, v in cell_type_dict.items()}[cell_type], rle))\n","            # Add the predicted mask to the list\n","            binary_mask_resized = cv2.resize(binary_mask, (HEIGHT, WIDTH), interpolation=cv2.INTER_NEAREST)\n","            pred_masks[num][cell_type-1, :, :] = binary_mask_resized[:, :]\n","\n","        # Add empty prediction if no RLE was generated for this image\n","        all_image_ids = [image_id for image_id, _, _ in predictions]\n","        if image_id not in all_image_ids:\n","            for key in cell_type_dict.keys():\n","                predictions.append((image_id, key, \"\"))\n","\n","    # Convert predictions to DataFrame\n","    df_preds = pd.DataFrame(predictions, columns=['id', 'class', 'predicted'])\n","\n","    return df_preds, true_masks, pred_masks"],"metadata":{"id":"qAXij8rP5mAe"},"id":"qAXij8rP5mAe","execution_count":null,"outputs":[]},{"cell_type":"code","source":["if INFERENCE:\n","    DATASET = 'val' # ['train', 'val', 'test']\n","\n","    if DATASET == 'train':\n","        dataloader = dl_train\n","    elif DATASET == 'val':\n","        dataloader = dl_val\n","    elif DATASET == 'test':\n","        dataloader = dl_test\n","    else:\n","        raise ValueError(\"Invalid dataset name. Please choose 'train', 'val', or 'test'.\")\n","\n","    print(f\"Inference for epoch:{e}'s model on {DATASET} set\")\n","\n","    dice_loss_meter = AverageMeter()\n","    hd_loss_meter = AverageMeter()\n","    iou_meter_0 = AverageMeter()\n","    iou_meter_1 = AverageMeter()\n","    iou_meter_2 = AverageMeter()\n","\n","    df_preds = pd.DataFrame(columns=['id', 'class', 'predicted'])\n","\n","    for i, (images, targets) in enumerate(dataloader):\n","        # Show current batch index\n","        print(f\"Batch: {i + 1} / {len(dataloader)} ({((i + 1) / len(dataloader)) * 100:.2f}%)\")\n","\n","        # Make predictions\n","        df_preds_batch, true_masks_batch, pred_masks_batch = inference(model, images, targets)\n","        df_preds = pd.concat([df_preds, df_preds_batch])\n","\n","        # Compute metrics\n","        dice_loss = DiceLoss(true_masks_batch, pred_masks_batch)\n","        # hd_loss = ChannelwiseHausdorffDistanceLoss(true_masks_batch, pred_masks_batch) # Hausdorff Distance Loss takes too long to compute, so we do not include it here.\n","        iou_0, iou_1, iou_2 = IoU(true_masks_batch, pred_masks_batch)\n","\n","        # Update metrics\n","        dice_loss_meter.update(dice_loss, len(images))\n","        # hd_loss_meter.update(hd_loss, len(images))\n","        iou_meter_0.update(iou_0, len(images))\n","        iou_meter_1.update(iou_1, len(images))\n","        iou_meter_2.update(iou_2, len(images))\n","\n","    # Show results\n","    print(f'Dice Loss: {dice_loss_meter.avg:.4f}')\n","    # print(f'Hausdorff Distance Loss: {hd_loss_meter.avg:.4f}')\n","    print(f'IoU - Stomach: {iou_meter_0.avg:.4f}')\n","    print(f'IoU - Large Bowel: {iou_meter_1.avg:.4f}')\n","    print(f'IoU - Small Bowel: {iou_meter_2.avg:.4f}')\n","\n","    # Store prediction results\n","    display(df_preds.head())\n","    df_preds.to_csv(f\"output/predictions/maskrcnn_preds_{DATASET}_e{e}.csv\", index=False)\n","\n","    # Store result metrics\n","    metrics = {\n","        'Epoch': e,\n","        'Dice Loss': dice_loss_meter.avg,\n","        # 'Hausdorff Distance Loss': hd_loss_meter.avg,\n","        'Stomach IoU': iou_meter_0.avg,\n","        'Large Bowel IoU': iou_meter_1.avg,\n","        'Small Bowel IoU': iou_meter_2.avg\n","    }\n","    df_metrics = pd.DataFrame(metrics, index=[0])\n","    # Check existing file\n","    if os.path.isfile(f\"output/metrics/maskrcnn_metrics_{DATASET}.csv\"):\n","        existing_df = pd.read_csv(f\"output/metrics/maskrcnn_metrics_{DATASET}.csv\")\n","        df_metrics = pd.concat([existing_df, df_metrics], ignore_index=True)\n","        df_metrics.to_csv(f\"output/metrics/maskrcnn_metrics_{DATASET}.csv\", index=False)\n","    else:\n","        df_metrics.to_csv(f\"output/metrics/maskrcnn_metrics_{DATASET}.csv\", index=False)"],"metadata":{"id":"kMTCS5C06s_r"},"id":"kMTCS5C06s_r","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"X2F_wEgC6YYv","metadata":{"id":"X2F_wEgC6YYv"},"source":["# Find Best Threshold"]},{"cell_type":"code","execution_count":null,"id":"llgCj1oT6cmE","metadata":{"id":"llgCj1oT6cmE"},"outputs":[],"source":["FIND_THRESHOLD = False"]},{"cell_type":"code","execution_count":null,"id":"22e0c240","metadata":{"id":"22e0c240"},"outputs":[],"source":["# Find best threshold based on validation dataset for each organ\n","if FIND_THRESHOLD:\n","  valid_data_threshold_analysis = pd.DataFrame(data = None, columns = ['stomach', 'large_bowel', 'small_bowel', 'IoU'])\n","  i = 0\n","  for stomach_prob in tqdm(range(45, 55, 5), desc='Stomach Probabilities'):\n","      for large_bowel_prob in range(45, 55, 5):\n","          for small_bowel_prob in range(45, 55, 5):\n","              mask_threshold_dict = {1: stomach_prob / 100, 2: large_bowel_prob / 100, 3: small_bowel_prob / 100}\n","              valid_data_threshold_analysis.loc[i] = stomach_prob / 100, large_bowel_prob / 100, small_bowel_prob / 100, get_score(ds_val, model, mask_threshold_dict)\n","              i += 1\n","  valid_data_threshold_analysis"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","toc_visible":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":23725.326068,"end_time":"2022-05-18T22:18:04.420867","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-05-18T15:42:39.094799","version":"2.3.4"}},"nbformat":4,"nbformat_minor":5}