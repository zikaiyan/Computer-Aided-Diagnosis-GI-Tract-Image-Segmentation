{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4061c2d-dca6-40a3-9549-ee86c6c70e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pycocotools\n",
    "from pycocotools import mask\n",
    "import pycocotools.mask as mask_util\n",
    "import numpy as np\n",
    "import json\n",
    "from pycocotools.coco import COCO\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib as mpl\n",
    "\n",
    "def np_encoder(object):\n",
    "    if isinstance(object, np.generic):\n",
    "        return object.item()\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib.colors import ListedColormap\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a53aed2-2bc3-4eed-a837-b6cf25d4f267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/srikaranreddy/Desktop/Spring Semester/Computer Vision 6.8300/cv-project/gi-tract-image-segmentation'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()\n",
    "\n",
    "os.chdir('../')\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6479bc3-0d51-4cf0-b685-2be944f30078",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import SegmentationDataset\n",
    "from src.data import DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d80a2d71-ac28-4138-b457-9761f92b7f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dice Loss\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        y_pred = y_pred.contiguous().view(-1)\n",
    "        y_true = y_true.contiguous().view(-1)\n",
    "        intersection = (y_pred * y_true).sum()\n",
    "        dice = (2. * intersection + self.smooth) / (y_pred.sum() + y_true.sum() + self.smooth)\n",
    "        return 1 - dice\n",
    "\n",
    "# Combined BCE and Dice Loss\n",
    "class BCEDiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1):\n",
    "        super(BCEDiceLoss, self).__init__()\n",
    "        self.bce = nn.BCEWithLogitsLoss()\n",
    "        self.dice = DiceLoss(smooth)\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        bce_loss = self.bce(y_pred, y_true)\n",
    "        dice_loss = self.dice(y_pred, y_true)\n",
    "        return 0.5 * bce_loss + 0.5 * dice_loss\n",
    "\n",
    "def dice_coef_func(y_true, y_pred, smooth=1):\n",
    "    y_true_f = y_true.contiguous().view(-1)\n",
    "    y_pred_f = y_pred.contiguous().view(-1)\n",
    "    intersection = torch.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (torch.sum(y_true_f) + torch.sum(y_pred_f) + smooth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0663d0d-9279-469c-bde0-ed6c92a3b3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator_class = DataGenerator(dataset_dir='datasets/train',\n",
    "                                     subset=\"train\",\n",
    "                                     classes=CLASSES,\n",
    "                                     input_image_size=(128,128),\n",
    "                                     annFile='datasets/coco/train_json.json',\n",
    "                                     shuffle=True)\n",
    "\n",
    "val_generator_class = DataGenerator(dataset_dir='datasets/train',\n",
    "                                     subset=\"train\",\n",
    "                                     classes=CLASSES,\n",
    "                                     input_image_size=(128,128),\n",
    "                                     annFile='datasets/coco/val_json.json',\n",
    "                                     shuffle=True)\n",
    "\n",
    "test_generator_class = DataGenerator(dataset_dir='datasets/train',\n",
    "                                     subset=\"test\",\n",
    "                                     classes=CLASSES,\n",
    "                                     input_image_size=(128,128),\n",
    "                                     annFile='datasets/coco/test_json.json',\n",
    "                                     shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf7df97-b4bc-4977-a6de-58dae1775498",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = train_generator_class.__getitem__(9)\n",
    "\n",
    "cmap = ListedColormap(['none', 'red'])  # 'none' is transparent, 'red' for the mask\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "# Display the image\n",
    "ax.imshow((X/255.)[:,:,0], cmap='gray')  # Use gray scale for the background image\n",
    "# Display the mask\n",
    "# The mask is added with 'alpha' for transparency so the image can be seen under the mask\n",
    "ax.imshow(y[:,:,1], cmap=cmap, alpha=0.5)  # Adjust alpha for more or less transparency\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4841e19-ceb7-4575-99d7-d63e4d1ec3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_generator_class, batch_size=32, num_workers=0)\n",
    "val_loader = DataLoader(val_generator_class, batch_size=32, num_workers=0)\n",
    "test_loader = DataLoader(test_generator_class, batch_size=32, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b604508f-5af7-4bd2-85cd-566a2b9fdf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Batch size:\", train_loader.batch_size)\n",
    "print(\"Num workers:\", train_loader.num_workers)\n",
    "print(\"Dataset size:\", len(train_loader.dataset))\n",
    "print(\"Number of batches:\", len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebee8a2-3086-428e-9a73-4c2b8c72623c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = smp.Unet(\n",
    "    encoder_name=\"efficientnet-b7\", \n",
    "    encoder_weights=\"imagenet\", \n",
    "    in_channels=3, \n",
    "    classes=3,\n",
    "    activation='sigmoid'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a045c9-8a2d-4d8d-a638-d799092a4dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb88a4f-95a6-48e0-9074-a8c7abf36717",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.2, patience=5, verbose=True, min_lr=0.001)\n",
    "criterion = BCEDiceLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abeb784-0156-4c08-9a65-8302adeaac60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_dice_coefs = []\n",
    "val_dice_coefs = []\n",
    "epochs = 5\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    dice_coef = 0 \n",
    "\n",
    "    dice_coef_meter = AverageMeter()\n",
    "    batches = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "    batches.set_description(\"Epoch NA: Loss (NA) Accuracy (NA %)\")\n",
    "    for batch_idx, (data, target) in batches:\n",
    "        data = data.permute(0, 3, 1, 2)\n",
    "        target = target.permute(0, 3, 1, 2)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        dice_coef = dice_coef_func(output, target)\n",
    "        dice_coef_meter.update(dice_coef)\n",
    "    \n",
    "    train_losses.append(train_loss / len(train_loader))\n",
    "    train_dice_coefs.append(dice_coef / len(train_loader))\n",
    "    batches.set_description(\n",
    "            \"Epoch {:d}: Loss ({:.2e}), Train Accuracy ({:02.0f}%)\".format(\n",
    "                epoch, train_loss, 100.0 * dice_coef_meter.avg\n",
    "            )\n",
    "        )\n",
    "\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        for data, target in tqdm(val_loader):\n",
    "            data = data.permute(0, 3, 1, 2)\n",
    "            target = target.permute(0, 3, 1, 2)\n",
    "            \n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            val_loss += loss.item()\n",
    "            dice_coef += dice_coef_func(output, target)\n",
    "\n",
    "    val_losses.append(val_loss / len(val_loader))\n",
    "    val_dice_coefs.append(dice_coef / len(val_loader))\n",
    "\n",
    "    print(f\"Epoch {epoch}, Val Loss: {val_loss}\")\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # Save model checkpoint\n",
    "    torch.save(model.state_dict(), f'UNET_model_epoch_{epoch}.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5e186d-9eb5-4d2b-b637-080c20cb599b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
